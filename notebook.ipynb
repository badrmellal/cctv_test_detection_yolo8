{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Key Features:\n",
    "- YOLOv8 Object Detection - YOLO model for accuracy\n",
    "- Line Crossing Detection - Counts people, cars, trucks, motorcycles crossing lines\n",
    "- OpenCV Integration - Full video processing pipeline\n",
    "- IP Camera Ready - RTSP stream support for cameras\n",
    "- Real-time Processing - Webcam and live stream analysis"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:48:52.113378Z",
     "start_time": "2025-05-28T18:47:12.869393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install and Import Dependencies\n",
    "!pip install ultralytics opencv-python pillow matplotlib numpy\n",
    "!pip install requests urllib3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up matplotlib for video display\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "print(\"All dependencies installed and imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.146-py3-none-any.whl.metadata (37 kB)\r\n",
      "Collecting opencv-python\r\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.12/site-packages (11.2.1)\r\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.3)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.6)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.32.3)\r\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\r\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\r\n",
      "Collecting torch>=1.8.0 (from ultralytics)\r\n",
      "  Using cached torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\r\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\r\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\r\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\r\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ultralytics) (7.0.0)\r\n",
      "Collecting py-cpuinfo (from ultralytics)\r\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.3)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.58.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\r\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\r\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.8.0->ultralytics)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Downloading ultralytics-8.3.146-py3-none-any.whl (1.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m704.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.3/37.3 MB\u001B[0m \u001B[31m572.0 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:03\u001B[0m\r\n",
      "\u001B[?25hUsing cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\r\n",
      "Using cached torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\r\n",
      "Downloading torchvision-0.22.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m658.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\r\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\r\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\r\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Installing collected packages: py-cpuinfo, mpmath, tqdm, sympy, scipy, opencv-python, networkx, fsspec, filelock, torch, ultralytics-thop, torchvision, ultralytics\r\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 mpmath-1.3.0 networkx-3.4.2 opencv-python-4.11.0.86 py-cpuinfo-9.0.0 scipy-1.15.3 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 tqdm-4.67.1 ultralytics-8.3.146 ultralytics-thop-2.0.14\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: urllib3 in ./.venv/lib/python3.12/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.4.26)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/Apple/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "✅ All dependencies installed and imported successfully!\n",
      "OpenCV version: 4.11.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:57:37.030386Z",
     "start_time": "2025-05-28T19:56:39.114774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pretrained YOLOv8 model and set up detection parameters\n",
    "class CCTVDetector:\n",
    "    def __init__(self, model_size='n'):\n",
    "        \"\"\"\n",
    "        Initialize CCTV detector with YOLO model\n",
    "        model_size: 'n' (nano), 's' (small), 'm' (medium), 'l' (large), 'x' (extra large)\n",
    "        \"\"\"\n",
    "        self.model = YOLO(f'yolov8{model_size}.pt')\n",
    "\n",
    "        # Target classes for CCTV monitoring (COCO dataset indices)\n",
    "        self.target_classes = {\n",
    "            0: 'person',\n",
    "            1: 'bicycle',\n",
    "            2: 'car',\n",
    "            3: 'motorcycle',\n",
    "            5: 'bus',\n",
    "            7: 'truck'\n",
    "        }\n",
    "\n",
    "        # Detection parameters\n",
    "        self.confidence_threshold = 0.5\n",
    "        self.nms_threshold = 0.4\n",
    "\n",
    "        # Tracking parameters\n",
    "        self.max_disappeared = 30\n",
    "        self.max_distance = 100\n",
    "\n",
    "        print(f\"YOLO model initialized: YOLOv8{model_size}\")\n",
    "        print(f\"Monitoring classes: {list(self.target_classes.values())}\")\n",
    "\n",
    "# Initialize detector\n",
    "detector = CCTVDetector(model_size='s')  # Used s for speed on my laptop"
   ],
   "id": "534deb1a25625cce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "WARNING ⚠️ Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#######################################################################   99.8%                                                     29.7%################                              61.6%####################################################     96.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO model initialized: YOLOv8s\n",
      "Monitoring classes: ['person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:59:33.007046Z",
     "start_time": "2025-05-28T19:59:33.000942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Implement line crossing detection and object counting logic\n",
    "class LineCrossingCounter:\n",
    "    def __init__(self, line_start, line_end, direction=\"both\"):\n",
    "        \"\"\"\n",
    "        Initialize line crossing counter\n",
    "        line_start: (x1, y1) start point of counting line\n",
    "        line_end: (x2, y2) end point of counting line\n",
    "        direction: \"both\", \"up\", \"down\", \"left\", \"right\"\n",
    "        \"\"\"\n",
    "        self.line_start = line_start\n",
    "        self.line_end = line_end\n",
    "        self.direction = direction\n",
    "\n",
    "        # Counting variables\n",
    "        self.crossings = defaultdict(int)  # Count by object class\n",
    "        self.total_crossings = 0\n",
    "\n",
    "        # Tracking variables\n",
    "        self.tracked_objects = {}\n",
    "        self.next_object_id = 0\n",
    "\n",
    "        # History for direction detection\n",
    "        self.position_history = defaultdict(lambda: deque(maxlen=10))\n",
    "\n",
    "    def point_line_side(self, point, line_start, line_end):\n",
    "        \"\"\"Determine which side of line a point is on\"\"\"\n",
    "        return ((line_end[0] - line_start[0]) * (point[1] - line_start[1]) -\n",
    "                (line_end[1] - line_start[1]) * (point[0] - line_start[0]))\n",
    "\n",
    "    def has_crossed_line(self, prev_pos, curr_pos):\n",
    "        \"\"\"Check if object crossed the counting line\"\"\"\n",
    "        if prev_pos is None or curr_pos is None:\n",
    "            return False\n",
    "\n",
    "        prev_side = self.point_line_side(prev_pos, self.line_start, self.line_end)\n",
    "        curr_side = self.point_line_side(curr_pos, self.line_start, self.line_end)\n",
    "\n",
    "        # Check if signs are different (crossed line)\n",
    "        return (prev_side > 0) != (curr_side > 0)\n",
    "\n",
    "    def update_tracking(self, detections):\n",
    "        \"\"\"Update object tracking and check for line crossings\"\"\"\n",
    "        current_centroids = []\n",
    "        current_classes = []\n",
    "\n",
    "        # Extract centroids and classes from detections\n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2, conf, cls = detection\n",
    "            centroid = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "            current_centroids.append(centroid)\n",
    "            current_classes.append(int(cls))\n",
    "\n",
    "        # Simple tracking based on nearest neighbor\n",
    "        if len(current_centroids) == 0:\n",
    "            return\n",
    "\n",
    "        # Update existing tracks or create new ones\n",
    "        for i, (centroid, cls) in enumerate(zip(current_centroids, current_classes)):\n",
    "            # Find closest existing track\n",
    "            min_distance = float('inf')\n",
    "            closest_id = None\n",
    "\n",
    "            for obj_id, (prev_centroid, prev_cls) in self.tracked_objects.items():\n",
    "                if cls == prev_cls:  # Only match same class\n",
    "                    distance = np.sqrt((centroid[0] - prev_centroid[0])**2 +\n",
    "                                     (centroid[1] - prev_centroid[1])**2)\n",
    "                    if distance < min_distance and distance < self.next_object_id:\n",
    "                        min_distance = distance\n",
    "                        closest_id = obj_id\n",
    "\n",
    "            # Update existing track or create new one\n",
    "            if closest_id is not None and min_distance < 100:\n",
    "                obj_id = closest_id\n",
    "                prev_centroid = self.tracked_objects[obj_id][0]\n",
    "\n",
    "                # Check for line crossing\n",
    "                if self.has_crossed_line(prev_centroid, centroid):\n",
    "                    class_name = detector.target_classes.get(cls, f'class_{cls}')\n",
    "                    self.crossings[class_name] += 1\n",
    "                    self.total_crossings += 1\n",
    "                    print(f\"🚨 {class_name} crossed the line! Total: {self.total_crossings}\")\n",
    "\n",
    "                self.tracked_objects[obj_id] = (centroid, cls)\n",
    "            else:\n",
    "                # Create new track\n",
    "                self.tracked_objects[self.next_object_id] = (centroid, cls)\n",
    "                self.next_object_id += 1"
   ],
   "id": "9f54609f8c354362",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T20:00:52.395045Z",
     "start_time": "2025-05-28T20:00:52.389736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Core video processing and detection pipeline\n",
    "def process_frame(frame, detector, line_counter, show_line=True):\n",
    "    \"\"\"\n",
    "    Process single frame: detect objects, draw bounding boxes, update counting\n",
    "    \"\"\"\n",
    "    # Run YOLO detection\n",
    "    results = detector.model(frame, conf=detector.confidence_threshold)\n",
    "\n",
    "    # Extract detections\n",
    "    detections = []\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                # Extract box coordinates and info\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "\n",
    "                # Only process target classes\n",
    "                if class_id in detector.target_classes:\n",
    "                    detections.append([x1, y1, x2, y2, confidence, class_id])\n",
    "\n",
    "                    # Draw bounding box\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                    cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "\n",
    "                    # Draw label\n",
    "                    label = f\"{detector.target_classes[class_id]}: {confidence:.2f}\"\n",
    "                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                    cv2.rectangle(annotated_frame, (int(x1), int(y1) - label_size[1] - 5),\n",
    "                                (int(x1) + label_size[0], int(y1)), color, -1)\n",
    "                    cv2.putText(annotated_frame, label, (int(x1), int(y1) - 5),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    # Update line crossing detection\n",
    "    line_counter.update_tracking(detections)\n",
    "\n",
    "    # Draw counting line\n",
    "    if show_line:\n",
    "        cv2.line(annotated_frame, line_counter.line_start, line_counter.line_end, (0, 0, 255), 3)\n",
    "        cv2.putText(annotated_frame, \"COUNTING LINE\",\n",
    "                   (line_counter.line_start[0], line_counter.line_start[1] - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Draw statistics\n",
    "    y_offset = 30\n",
    "    cv2.putText(annotated_frame, f\"Total Crossings: {line_counter.total_crossings}\",\n",
    "               (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    y_offset += 30\n",
    "    for class_name, count in line_counter.crossings.items():\n",
    "        cv2.putText(annotated_frame, f\"{class_name}: {count}\",\n",
    "                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        y_offset += 25\n",
    "\n",
    "    return annotated_frame, detections"
   ],
   "id": "43fab40b2a82299f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:39:06.870044Z",
     "start_time": "2025-05-28T23:38:13.328377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download sample CCTV traffic video for demonstration\n",
    "def download_free_cctv_videos():\n",
    "    \"\"\"Download free CCTV footage - Just run this!\"\"\"\n",
    "\n",
    "    # Free CCTV-style videos (no copyright issues)\n",
    "    free_videos = {\n",
    "        'traffic_intersection.mp4': 'https://videos.pexels.com/video-files/2103099/2103099-hd_1920_1080_30fps.mp4',\n",
    "        'street_crossing.mp4': 'https://videos.pexels.com/video-files/1721294/1721294-hd_1920_1080_25fps.mp4',\n",
    "        'parking_lot.mp4': 'https://videos.pexels.com/video-files/2169880/2169880-hd_1920_1080_30fps.mp4',\n",
    "        'busy_street.mp4': 'https://videos.pexels.com/video-files/3571264/3571264-hd_1920_1080_30fps.mp4'\n",
    "    }\n",
    "\n",
    "    # Create folder\n",
    "    os.makedirs('cctv_test_videos', exist_ok=True)\n",
    "\n",
    "    print(\"Downloading CCTV footage...\")\n",
    "\n",
    "    for filename, url in free_videos.items():\n",
    "        try:\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                filepath = f'cctv_test_videos/{filename}'\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                print(f\" Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\" Failed: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error downloading {filename}: {e}\")\n",
    "\n",
    "    return 'cctv_test_videos'\n",
    "\n",
    "video_folder = download_free_cctv_videos()"
   ],
   "id": "c5d0e04d512cf7e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CCTV footage...\n",
      "Downloading traffic_intersection.mp4...\n",
      " Downloaded: traffic_intersection.mp4\n",
      "Downloading street_crossing.mp4...\n",
      " Downloaded: street_crossing.mp4\n",
      "Downloading parking_lot.mp4...\n",
      " Downloaded: parking_lot.mp4\n",
      "Downloading busy_street.mp4...\n",
      " Downloaded: busy_street.mp4\n",
      "\n",
      " Testing detection on cctv_test_videos/traffic_intersection.mp4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'analyze_cctv_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 63\u001B[39m\n\u001B[32m     59\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     60\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m Video not found. Run download_free_cctv_videos() first\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m \u001B[43mtest_with_downloaded_video\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 52\u001B[39m, in \u001B[36mtest_with_downloaded_video\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     49\u001B[39m line_end = (\u001B[32m800\u001B[39m, \u001B[32m300\u001B[39m)    \u001B[38;5;66;03m# Right side of line\u001B[39;00m\n\u001B[32m     51\u001B[39m \u001B[38;5;66;03m# Run analysis\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m results = \u001B[43manalyze_cctv_video\u001B[49m(test_video, line_start, line_end, max_frames=\u001B[32m200\u001B[39m)\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m results:\n\u001B[32m     55\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m📊 Results:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'analyze_cctv_video' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:42:07.223605Z",
     "start_time": "2025-05-28T23:42:07.219202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process sample video with object detection and line crossing\n",
    "def analyze_cctv_video(video_path, line_start=(400, 200), line_end=(400, 400),\n",
    "                      max_frames=300, save_output=True):\n",
    "    \"\"\"\n",
    "    Analyze CCTV video with object detection and line crossing\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return None\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Video Info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "\n",
    "    # Initialize line counter (we can adjust coordinates based on video)\n",
    "    line_counter = LineCrossingCounter(line_start, line_end)\n",
    "\n",
    "    # Setup output video writer\n",
    "    output_path = \"analyzed_cctv_output.mp4\"\n",
    "    if save_output:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Process video frames\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Processing video frames...\")\n",
    "\n",
    "    try:\n",
    "        while frame_count < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process frame\n",
    "            processed_frame, detections = process_frame(frame, detector, line_counter)\n",
    "\n",
    "            # Save frame if output enabled\n",
    "            if save_output:\n",
    "                out.write(processed_frame)\n",
    "\n",
    "            # Display progress\n",
    "            if frame_count % 30 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                fps_current = frame_count / elapsed if elapsed > 0 else 0\n",
    "                print(f\"Frame {frame_count}/{max_frames}, FPS: {fps_current:.1f}, Crossings: {line_counter.total_crossings}\")\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Processing interrupted by user\")\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    if save_output:\n",
    "        out.release()\n",
    "        print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "    # Print final statistics\n",
    "    print(\"\\n Final Analysis Results:\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total line crossings: {line_counter.total_crossings}\")\n",
    "    print(\"Crossings by object type:\")\n",
    "    for class_name, count in line_counter.crossings.items():\n",
    "        print(f\"  {class_name}: {count}\")\n",
    "\n",
    "    return line_counter\n"
   ],
   "id": "33ed35fe578fb555",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Real-time object detection using built-in webcam for later don't run this cell !!!\n",
    "def real_time_detection(camera_index=0, line_position=0.5):\n",
    "    \"\"\"\n",
    "    Real-time object detection using webcam\n",
    "    camera_index: 0 for built-in camera, 1 for external\n",
    "    line_position: vertical position of counting line (0.0-1.0)\n",
    "    \"\"\"\n",
    "    # Initialize camera\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Cannot open camera\")\n",
    "        return\n",
    "\n",
    "    # Get camera resolution\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Setup counting line (horizontal line across middle)\n",
    "    line_y = int(height * line_position)\n",
    "    line_counter = LineCrossingCounter((0, line_y), (width, line_y))\n",
    "\n",
    "    print(\"📹 Starting real-time detection...\")\n",
    "    print(\"Press 'q' to quit, 'r' to reset counters\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process frame\n",
    "            processed_frame, _ = process_frame(frame, detector, line_counter)\n",
    "\n",
    "            # Display frame\n",
    "            cv2.imshow('CCTV Object Detection', processed_frame)\n",
    "\n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                line_counter.crossings.clear()\n",
    "                line_counter.total_crossings = 0\n",
    "                print(\"Counters reset\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Detection stopped by user\")\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return line_counter\n",
    "\n",
    "# Uncomment to run real-time detection\n",
    "# real_time_results = real_time_detection()"
   ],
   "id": "9f92065b628d8dcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Functions for connecting to IP cameras and RTSP streams don't this until previous cell is up and running guys !!\n",
    "\n",
    "class IPCameraHandler:\n",
    "    def __init__(self):\n",
    "        self.supported_formats = [\n",
    "            \"rtsp://username:password@ip_address:port/stream\",\n",
    "            \"http://ip_address:port/video.mjpg\",\n",
    "            \"rtsp://ip_address:port/live.sdp\"\n",
    "        ]\n",
    "\n",
    "    def connect_ip_camera(self, camera_url, timeout=10):\n",
    "        \"\"\"\n",
    "        Connect to IP camera using URL\n",
    "        Common formats:\n",
    "        - RTSP: rtsp://admin:password@192.168.1.100:554/stream1\n",
    "        - HTTP: http://192.168.1.100:8080/video.mjpg\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(camera_url)\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Reduce latency\n",
    "\n",
    "            # Test connection\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                print(f\"Successfully connected to IP camera: {camera_url}\")\n",
    "                height, width = frame.shape[:2]\n",
    "                print(f\"Stream resolution: {width}x{height}\")\n",
    "                return cap\n",
    "            else:\n",
    "                print(f\"Failed to read from IP camera: {camera_url}\")\n",
    "                cap.release()\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to IP camera: {e}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_ip_stream(self, camera_url, line_start=None, line_end=None,\n",
    "                         duration_minutes=5):\n",
    "        \"\"\"\n",
    "        Analyze IP camera stream for specified duration\n",
    "        \"\"\"\n",
    "        cap = self.connect_ip_camera(camera_url)\n",
    "        if cap is None:\n",
    "            return None\n",
    "\n",
    "        # Get stream properties\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Default line position if not specified\n",
    "        if line_start is None:\n",
    "            line_start = (width // 4, height // 2)\n",
    "        if line_end is None:\n",
    "            line_end = (3 * width // 4, height // 2)\n",
    "\n",
    "        # Initialize line counter\n",
    "        line_counter = LineCrossingCounter(line_start, line_end)\n",
    "\n",
    "        # Analysis parameters\n",
    "        start_time = time.time()\n",
    "        duration_seconds = duration_minutes * 60\n",
    "        frame_count = 0\n",
    "\n",
    "        print(f\"Analyzing IP stream for {duration_minutes} minutes...\")\n",
    "        print(\"Press Ctrl+C to stop early\")\n",
    "\n",
    "        try:\n",
    "            while time.time() - start_time < duration_seconds:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"⚠️ Lost connection to IP camera\")\n",
    "                    break\n",
    "\n",
    "                # Process frame\n",
    "                processed_frame, _ = process_frame(frame, detector, line_counter)\n",
    "\n",
    "                # Optional: Display frame (comment out for headless operation)\n",
    "                # cv2.imshow('IP Camera Analysis', processed_frame)\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                #     break\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # Progress update every 30 seconds\n",
    "                if frame_count % 900 == 0:  # Assuming ~30 FPS\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"Elapsed: {elapsed/60:.1f}min, Crossings: {line_counter.total_crossings}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"⏹️ Analysis stopped by user\")\n",
    "\n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return line_counter\n",
    "\n",
    "# Initialize IP camera handler\n",
    "ip_camera = IPCameraHandler()\n",
    "\n",
    "# Example usage (uncomment and modify URL to use)\n",
    "# ip_results = ip_camera.analyze_ip_stream(\"rtsp://admin:password@192.168.1.100:554/stream1\")\n"
   ],
   "id": "cb3fc9daf70f9372"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:45:03.939499Z",
     "start_time": "2025-05-28T23:45:03.935792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure detection parameters and advanced features\n",
    "class AdvancedDetectionConfig:\n",
    "    def __init__(self):\n",
    "        self.detection_zones = []\n",
    "        self.alert_settings = {\n",
    "            'max_objects': 10,\n",
    "            'crowding_threshold': 5,\n",
    "            'speed_detection': True\n",
    "        }\n",
    "        self.recording_settings = {\n",
    "            'record_detections': True,\n",
    "            'save_snapshots': True,\n",
    "            'alert_video_length': 10  # seconds\n",
    "        }\n",
    "\n",
    "    def add_detection_zone(self, points, zone_name=\"Zone1\"):\n",
    "        \"\"\"Add polygon detection zone\"\"\"\n",
    "        self.detection_zones.append({\n",
    "            'name': zone_name,\n",
    "            'points': np.array(points, dtype=np.int32),\n",
    "            'crossings': 0\n",
    "        })\n",
    "\n",
    "    def point_in_polygon(self, point, polygon):\n",
    "        \"\"\"Check if point is inside polygon zone\"\"\"\n",
    "        return cv2.pointPolygonTest(polygon, point, False) >= 0\n",
    "\n",
    "    def analyze_zones(self, detections):\n",
    "        \"\"\"Analyze detections within defined zones\"\"\"\n",
    "        zone_counts = {}\n",
    "\n",
    "        for zone in self.detection_zones:\n",
    "            count = 0\n",
    "            for detection in detections:\n",
    "                x1, y1, x2, y2, conf, cls = detection\n",
    "                center = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "                if self.point_in_polygon(center, zone['points']):\n",
    "                    count += 1\n",
    "\n",
    "            zone_counts[zone['name']] = count\n",
    "\n",
    "        return zone_counts\n",
    "\n",
    "# Initialize advanced configuration\n",
    "advanced_config = AdvancedDetectionConfig()\n",
    "\n",
    "# Example: Add detection zones (modify coordinates as needed)\n",
    "# advanced_config.add_detection_zone([(100, 100), (300, 100), (300, 300), (100, 300)], \"Entrance\")\n",
    "# advanced_config.add_detection_zone([(400, 200), (600, 200), (600, 400), (400, 400)], \"Parking\")\n"
   ],
   "id": "562d4c40cd6b29e4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:45:10.426484Z",
     "start_time": "2025-05-28T23:45:10.422924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Monitor detection performance and generate statistics\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.frame_times = deque(maxlen=100)\n",
    "        self.detection_counts = deque(maxlen=1000)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def update(self, frame_time, detection_count):\n",
    "        \"\"\"Update performance metrics\"\"\"\n",
    "        self.frame_times.append(frame_time)\n",
    "        self.detection_counts.append(detection_count)\n",
    "\n",
    "    def get_fps(self):\n",
    "        \"\"\"Calculate current FPS\"\"\"\n",
    "        if len(self.frame_times) < 2:\n",
    "            return 0\n",
    "        return len(self.frame_times) / sum(self.frame_times)\n",
    "\n",
    "    def get_average_detections(self):\n",
    "        \"\"\"Get average detections per frame\"\"\"\n",
    "        if not self.detection_counts:\n",
    "            return 0\n",
    "        return np.mean(self.detection_counts)\n",
    "\n",
    "    def get_runtime(self):\n",
    "        \"\"\"Get total runtime in minutes\"\"\"\n",
    "        return (time.time() - self.start_time) / 60\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate performance report\"\"\"\n",
    "        report = {\n",
    "            'runtime_minutes': self.get_runtime(),\n",
    "            'average_fps': self.get_fps(),\n",
    "            'average_detections_per_frame': self.get_average_detections(),\n",
    "            'total_frames_processed': len(self.frame_times),\n",
    "            'peak_detections': max(self.detection_counts) if self.detection_counts else 0\n",
    "        }\n",
    "        return report\n",
    "\n",
    "# Initialize performance monitor\n",
    "performance_monitor = PerformanceMonitor()"
   ],
   "id": "d34b0e37b51d80d5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:45:29.172060Z",
     "start_time": "2025-05-28T23:45:29.166816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Export detection data and create analysis reports\n",
    "class DataExporter:\n",
    "    def __init__(self, output_dir=\"cctv_analysis_output\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.detection_log = []\n",
    "\n",
    "    def log_detection(self, timestamp, object_type, position, confidence):\n",
    "        \"\"\"Log individual detection\"\"\"\n",
    "        self.detection_log.append({\n",
    "            'timestamp': timestamp,\n",
    "            'object_type': object_type,\n",
    "            'position': position,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "\n",
    "    def export_crossing_data(self, line_counter, filename=None):\n",
    "        \"\"\"Export line crossing data to CSV\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"crossings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(\"Object_Type,Crossings\\n\")\n",
    "            for obj_type, count in line_counter.crossings.items():\n",
    "                f.write(f\"{obj_type},{count}\\n\")\n",
    "            f.write(f\"Total,{line_counter.total_crossings}\\n\")\n",
    "\n",
    "        print(f\"📊 Crossing data exported to: {filepath}\")\n",
    "        return filepath\n",
    "\n",
    "    def create_summary_report(self, line_counter, performance_monitor):\n",
    "        \"\"\"Create comprehensive analysis report\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        performance_data = performance_monitor.generate_report()\n",
    "\n",
    "        report = f\"\"\"\n",
    "CCTV Analysis Report\n",
    "Generated: {timestamp}\n",
    "\n",
    "=== DETECTION SUMMARY ===\n",
    "Total Line Crossings: {line_counter.total_crossings}\n",
    "\n",
    "Crossings by Object Type:\n",
    "\"\"\"\n",
    "        for obj_type, count in line_counter.crossings.items():\n",
    "            report += f\"  {obj_type}: {count}\\n\"\n",
    "\n",
    "        report += f\"\"\"\n",
    "=== PERFORMANCE METRICS ===\n",
    "Runtime: {performance_data['runtime_minutes']:.1f} minutes\n",
    "Average FPS: {performance_data['average_fps']:.1f}\n",
    "Frames Processed: {performance_data['total_frames_processed']}\n",
    "Average Detections/Frame: {performance_data['average_detections_per_frame']:.1f}\n",
    "Peak Detections: {performance_data['peak_detections']}\n",
    "\n",
    "=== CONFIGURATION ===\n",
    "Model: YOLOv8 Nano\n",
    "Confidence Threshold: {detector.confidence_threshold}\n",
    "Target Classes: {list(detector.target_classes.values())}\n",
    "\"\"\"\n",
    "\n",
    "        # Save report\n",
    "        report_path = os.path.join(self.output_dir, f\"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "        print(f\"📋 Analysis report saved to: {report_path}\")\n",
    "        return report_path\n",
    "\n",
    "# Initialize data exporter\n",
    "data_exporter = DataExporter()"
   ],
   "id": "592e2bc24ca79286",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:46:15.120924Z",
     "start_time": "2025-05-28T23:46:15.114866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tools for configuring detection parameters and camera calibration\n",
    "def interactive_line_setup(video_path_or_camera=0):\n",
    "    \"\"\"\n",
    "    Interactive tool to set up counting line position\n",
    "    Click two points to define the counting line\n",
    "    \"\"\"\n",
    "    # Global variables for mouse callback\n",
    "    points = []\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            print(f\"Point {len(points)}: ({x}, {y})\")\n",
    "\n",
    "    # Open video or camera\n",
    "    if isinstance(video_path_or_camera, str):\n",
    "        cap = cv2.VideoCapture(video_path_or_camera)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(video_path_or_camera)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video source\")\n",
    "        return None, None\n",
    "\n",
    "    # Get first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot read from video source\")\n",
    "        return None, None\n",
    "\n",
    "    # Setup window and mouse callback\n",
    "    cv2.namedWindow('Setup Counting Line')\n",
    "    cv2.setMouseCallback('Setup Counting Line', mouse_callback)\n",
    "\n",
    "    print(\"Click two points to define the counting line\")\n",
    "    print(\"Press 'r' to reset, 'q' to confirm and quit\")\n",
    "\n",
    "    while len(points) < 2:\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        # Draw existing points\n",
    "        for i, point in enumerate(points):\n",
    "            cv2.circle(display_frame, point, 5, (0, 255, 0), -1)\n",
    "            cv2.putText(display_frame, f\"P{i+1}\", (point[0]+10, point[1]),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw line if we have both points\n",
    "        if len(points) == 2:\n",
    "            cv2.line(display_frame, points[0], points[1], (0, 0, 255), 2)\n",
    "            cv2.putText(display_frame, \"Press 'q' to confirm\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Setup Counting Line', display_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('r'):\n",
    "            points.clear()\n",
    "            print(\"Points reset\")\n",
    "        elif key == ord('q') and len(points) == 2:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "    if len(points) == 2:\n",
    "        print(f\"Counting line configured: {points[0]} to {points[1]}\")\n",
    "        return points[0], points[1]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def calibrate_detection_settings():\n",
    "    \"\"\"\n",
    "    Interactive calibration for detection settings\n",
    "    \"\"\"\n",
    "    print(\"Detection Settings Calibration\")\n",
    "    print(\"Current settings:\")\n",
    "    print(f\"  Confidence threshold: {detector.confidence_threshold}\")\n",
    "    print(f\"  Target classes: {list(detector.target_classes.values())}\")\n",
    "\n",
    "    # Allow user to adjust settings\n",
    "    new_confidence = input(f\"Enter new confidence threshold (current: {detector.confidence_threshold}): \")\n",
    "    if new_confidence:\n",
    "        try:\n",
    "            detector.confidence_threshold = float(new_confidence)\n",
    "            print(f\"Confidence threshold updated to: {detector.confidence_threshold}\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid value, keeping current setting\")\n",
    "\n",
    "    print(\"Calibration complete\")\n",
    "\n",
    "# Example: Set up counting line interactively (uncomment to use)\n",
    "# line_start, line_end = interactive_line_setup(sample_video_path)"
   ],
   "id": "8a6411cfa9c77d01",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:48:25.271772Z",
     "start_time": "2025-05-28T23:48:14.608876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Functions to test with my provided video files\n",
    "def test_custom_video(video_path, line_coordinates=None, max_duration_minutes=2):\n",
    "    \"\"\"\n",
    "    Test detection system with custom video file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # Get video properties\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    print(f\" Testing video: {video_path}\")\n",
    "    print(f\"   Resolution: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "\n",
    "    # Set default line coordinates if not provided\n",
    "    if line_coordinates is None:\n",
    "        line_start = (width // 4, height // 2)\n",
    "        line_end = (3 * width // 4, height // 2)\n",
    "    else:\n",
    "        line_start, line_end = line_coordinates\n",
    "\n",
    "    # Run analysis\n",
    "    max_frames = int(fps * max_duration_minutes * 60)\n",
    "    results = analyze_cctv_video(video_path, line_start, line_end, max_frames)\n",
    "\n",
    "    return results\n",
    "\n",
    "def batch_process_videos(video_directory, output_summary=True):\n",
    "    \"\"\"\n",
    "    Process multiple video files in a directory\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_directory):\n",
    "        print(f\"Directory not found: {video_directory}\")\n",
    "        return\n",
    "\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv']\n",
    "    video_files = []\n",
    "\n",
    "    # Find video files\n",
    "    for file in os.listdir(video_directory):\n",
    "        if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "            video_files.append(os.path.join(video_directory, file))\n",
    "\n",
    "    if not video_files:\n",
    "        print(f\"No video files found in {video_directory}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "    # Process each video\n",
    "    all_results = {}\n",
    "    for video_path in video_files:\n",
    "        print(f\"\\n Processing: {os.path.basename(video_path)}\")\n",
    "        result = test_custom_video(video_path, max_duration_minutes=1)\n",
    "        if result:\n",
    "            all_results[os.path.basename(video_path)] = result\n",
    "\n",
    "    # Create summary report\n",
    "    if output_summary and all_results:\n",
    "        print(f\"\\n Batch Processing Summary:\")\n",
    "        print(\"-\" * 50)\n",
    "        for filename, result in all_results.items():\n",
    "            print(f\"{filename}: {result.total_crossings} crossings\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Example usage\n",
    "def test_with_downloaded_video():\n",
    "    \"\"\"Test detection with downloaded video\"\"\"\n",
    "    test_video = 'cctv_test_videos/traffic_intersection.mp4'\n",
    "\n",
    "    if os.path.exists(test_video):\n",
    "        print(f\"\\n Testing detection on {test_video}\")\n",
    "\n",
    "        # Set counting line (adjust these coordinates as needed)\n",
    "        line_start = (400, 300)  # Left side of line\n",
    "        line_end = (800, 300)    # Right side of line\n",
    "\n",
    "        # Run analysis\n",
    "        results = analyze_cctv_video(test_video, line_start, line_end, max_frames=200)\n",
    "\n",
    "        if results:\n",
    "            print(f\"\\n Results:\")\n",
    "            print(f\"Total crossings: {results.total_crossings}\")\n",
    "            for obj_type, count in results.crossings.items():\n",
    "                print(f\"{obj_type}: {count}\")\n",
    "    else:\n",
    "        print(\"Video not found. Run download_free_cctv_videos() first\")\n",
    "\n",
    "# Run the test:\n",
    "test_with_downloaded_video()"
   ],
   "id": "856f2c98d7c71fce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing detection on cctv_test_videos/traffic_intersection.mp4\n",
      "Video Info: 1920x1080, 30 FPS, 1800 frames\n",
      "🔄 Processing video frames...\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 0/200, FPS: 0.0, Crossings: 0\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 38.2ms\n",
      "Speed: 1.5ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 trucks, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 trucks, 35.8ms\n",
      "Speed: 1.1ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 36.3ms\n",
      "Speed: 1.0ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 1\n",
      "\n",
      "0: 384x640 11 cars, 4 trucks, 35.4ms\n",
      "Speed: 1.3ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 2\n",
      "\n",
      "0: 384x640 11 cars, 3 trucks, 37.6ms\n",
      "Speed: 1.2ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 4 trucks, 35.4ms\n",
      "Speed: 1.3ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 3\n",
      "\n",
      "0: 384x640 12 cars, 4 trucks, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 4\n",
      "\n",
      "0: 384x640 14 cars, 4 trucks, 34.6ms\n",
      "Speed: 1.3ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 5\n",
      "\n",
      "0: 384x640 12 cars, 4 trucks, 37.1ms\n",
      "Speed: 1.3ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 6\n",
      "\n",
      "0: 384x640 14 cars, 4 trucks, 37.1ms\n",
      "Speed: 1.3ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 4 trucks, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 7\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 35.6ms\n",
      "Speed: 1.4ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 36.5ms\n",
      "Speed: 1.1ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 36.3ms\n",
      "Speed: 1.4ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 37.7ms\n",
      "Speed: 1.2ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 33.6ms\n",
      "Speed: 1.2ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 trucks, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 34.5ms\n",
      "Speed: 1.4ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 35.8ms\n",
      "Speed: 1.3ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 8\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 36.9ms\n",
      "Speed: 1.3ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 38.4ms\n",
      "Speed: 1.4ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 9\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 38.2ms\n",
      "Speed: 1.2ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 35.8ms\n",
      "Speed: 1.7ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 36.4ms\n",
      "Speed: 1.3ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 trucks, 35.8ms\n",
      "Speed: 1.0ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 36.8ms\n",
      "Speed: 1.4ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 35.7ms\n",
      "Speed: 1.3ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 30/200, FPS: 12.7, Crossings: 9\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 35.2ms\n",
      "Speed: 1.6ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.0ms\n",
      "Speed: 1.3ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 3 trucks, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 34.9ms\n",
      "Speed: 1.5ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 33.9ms\n",
      "Speed: 1.2ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 35.0ms\n",
      "Speed: 1.3ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 trucks, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 1 truck, 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 trucks, 35.3ms\n",
      "Speed: 1.6ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 34.8ms\n",
      "Speed: 1.1ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.0ms\n",
      "Speed: 1.3ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 36.6ms\n",
      "Speed: 1.4ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 36.5ms\n",
      "Speed: 1.4ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 4 trucks, 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.9ms\n",
      "Speed: 1.1ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 2 trucks, 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 1 truck, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 37.2ms\n",
      "Speed: 1.1ms preprocess, 37.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 36.6ms\n",
      "Speed: 1.2ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 35.1ms\n",
      "Speed: 1.2ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 60/200, FPS: 15.7, Crossings: 9\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 1 truck, 37.1ms\n",
      "Speed: 1.1ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 2 trucks, 37.8ms\n",
      "Speed: 1.2ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 37.1ms\n",
      "Speed: 1.4ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 36.8ms\n",
      "Speed: 1.0ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 10\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 2 trucks, 35.6ms\n",
      "Speed: 1.1ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 11\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 36.4ms\n",
      "Speed: 1.2ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 trucks, 35.5ms\n",
      "Speed: 1.1ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.2ms\n",
      "Speed: 1.2ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 3 trucks, 35.5ms\n",
      "Speed: 1.3ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "🚨 truck crossed the line! Total: 12\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 35.4ms\n",
      "Speed: 1.4ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 35.5ms\n",
      "Speed: 1.1ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.0ms\n",
      "Speed: 1.3ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 36.3ms\n",
      "Speed: 1.5ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 35.7ms\n",
      "Speed: 1.3ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 2 trucks, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 90/200, FPS: 16.9, Crossings: 12\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 1 truck, 35.1ms\n",
      "Speed: 1.3ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 37.3ms\n",
      "Speed: 1.2ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 35.2ms\n",
      "Speed: 1.3ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 37.1ms\n",
      "Speed: 1.1ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 34.4ms\n",
      "Speed: 1.1ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.0ms\n",
      "Speed: 1.1ms preprocess, 36.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.4ms\n",
      "Speed: 1.3ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.3ms\n",
      "Speed: 1.3ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.0ms\n",
      "Speed: 1.5ms preprocess, 36.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.8ms\n",
      "Speed: 1.3ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 34.0ms\n",
      "Speed: 1.2ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 34.9ms\n",
      "Speed: 1.6ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 34.6ms\n",
      "Speed: 1.3ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 37.7ms\n",
      "Speed: 1.1ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 35.5ms\n",
      "Speed: 1.2ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 35.3ms\n",
      "Speed: 1.4ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 120/200, FPS: 17.7, Crossings: 12\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 36.5ms\n",
      "Speed: 1.1ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.8ms\n",
      "Speed: 1.1ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 33.9ms\n",
      "Speed: 1.1ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.9ms\n",
      "Speed: 1.4ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.9ms\n",
      "Speed: 1.4ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.5ms\n",
      "Speed: 1.2ms preprocess, 35.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 33.8ms\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.1ms\n",
      "Speed: 1.2ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.0ms\n",
      "Speed: 1.2ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.8ms\n",
      "Speed: 1.1ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.1ms\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 35.4ms\n",
      "Speed: 1.4ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 150/200, FPS: 18.2, Crossings: 12\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 truck, 34.2ms\n",
      "Speed: 1.2ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 34.4ms\n",
      "Speed: 1.1ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 34.2ms\n",
      "Speed: 1.2ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.5ms\n",
      "Speed: 1.2ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.7ms\n",
      "Speed: 1.1ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.1ms\n",
      "Speed: 1.5ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.3ms\n",
      "Speed: 1.3ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.8ms\n",
      "Speed: 1.1ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 35.5ms\n",
      "Speed: 1.2ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 36.0ms\n",
      "Speed: 1.3ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 truck, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.4ms\n",
      "Speed: 1.2ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.1ms\n",
      "Speed: 1.2ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 34.5ms\n",
      "Speed: 1.4ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Frame 180/200, FPS: 18.6, Crossings: 12\n",
      "\n",
      "0: 384x640 13 cars, 2 trucks, 35.5ms\n",
      "Speed: 1.1ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.8ms\n",
      "Speed: 1.5ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 trucks, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 37.1ms\n",
      "Speed: 1.2ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 34.6ms\n",
      "Speed: 1.3ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 34.2ms\n",
      "Speed: 1.3ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 truck, 36.4ms\n",
      "Speed: 1.1ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 truck, 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 truck, 36.7ms\n",
      "Speed: 1.1ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "💾 Output saved to: analyzed_cctv_output.mp4\n",
      "\n",
      "📊 Final Analysis Results:\n",
      "Total frames processed: 200\n",
      "Total line crossings: 12\n",
      "Crossings by object type:\n",
      "  truck: 12\n",
      "\n",
      " Results:\n",
      "Total crossings: 12\n",
      "truck: 12\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:50:10.510502Z",
     "start_time": "2025-05-28T23:50:10.491014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Optimize settings for any device (CUDA, MPS, CPU)\n",
    "def optimize_for_device():\n",
    "    \"\"\"\n",
    "    Automatically detect and optimize YOLO detection for available hardware\n",
    "    \"\"\"\n",
    "    print(\" Detecting optimal device configuration...\")\n",
    "\n",
    "    # Detect best available device\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"Using CUDA GPU: {device_name}\")\n",
    "        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"   GPU Memory: {memory_gb:.1f} GB\")\n",
    "    elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"Using Metal Performance Shaders (MPS) - Apple Silicon\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\" Using CPU\")\n",
    "\n",
    "    # Device-specific optimization settings\n",
    "    if device == 'cuda':\n",
    "        optimal_settings = {\n",
    "            'model_size': 's',  # Small model for CUDA\n",
    "            'confidence_threshold': 0.5,\n",
    "            'input_resolution': (832, 832),  # Higher resolution for GPU\n",
    "            'batch_size': 4,\n",
    "            'max_fps': 60\n",
    "        }\n",
    "        performance_tips = [\n",
    "            \"GPU detected - using optimized settings for CUDA\",\n",
    "            \"Higher resolution and batch size enabled\",\n",
    "            \"Monitor GPU temperature and memory usage\",\n",
    "            \"Consider using larger model (YOLOv8s/m) for better accuracy\"\n",
    "        ]\n",
    "    elif device == 'mps':\n",
    "        optimal_settings = {\n",
    "            'model_size': 'n',  # Nano for MPS\n",
    "            'confidence_threshold': 0.5,\n",
    "            'input_resolution': (640, 640),\n",
    "            'batch_size': 1,\n",
    "            'max_fps': 30\n",
    "        }\n",
    "        performance_tips = [\n",
    "            \"Apple Silicon detected - optimized for MPS\",\n",
    "            \"Nano model recommended for real-time performance\",\n",
    "            \"Monitor thermal throttling on sustained loads\",\n",
    "            \"Close other applications to maximize performance\"\n",
    "        ]\n",
    "    else:  # CPU\n",
    "        optimal_settings = {\n",
    "            'model_size': 'n',  # Nano for CPU\n",
    "            'confidence_threshold': 0.6,  # Slightly higher to reduce processing\n",
    "            'input_resolution': (416, 416),  # Lower resolution for CPU\n",
    "            'batch_size': 1,\n",
    "            'max_fps': 15\n",
    "        }\n",
    "        performance_tips = [\n",
    "            \"CPU mode - optimized for lower computational load\",\n",
    "            \"Reduced resolution and FPS for better performance\",\n",
    "            \"Consider upgrading to GPU for real-time applications\",\n",
    "            \"Use threading for better CPU utilization\"\n",
    "        ]\n",
    "\n",
    "    # Apply optimizations\n",
    "    detector.confidence_threshold = optimal_settings['confidence_threshold']\n",
    "\n",
    "    print(f\"\\n Optimization settings for {device.upper()}:\")\n",
    "    for setting, value in optimal_settings.items():\n",
    "        print(f\"   {setting}: {value}\")\n",
    "\n",
    "    print(f\"\\n Device-specific Performance Tips:\")\n",
    "    for tip in performance_tips:\n",
    "        print(f\"   • {tip}\")\n",
    "\n",
    "    return device, optimal_settings\n",
    "\n",
    "# Apply device-specific optimizations\n",
    "current_device, device_settings = optimize_for_device()"
   ],
   "id": "1e856769a07f909c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Detecting optimal device configuration...\n",
      "Using Metal Performance Shaders (MPS) - Apple Silicon\n",
      "\n",
      " Optimization settings for MPS:\n",
      "   model_size: n\n",
      "   confidence_threshold: 0.5\n",
      "   input_resolution: (640, 640)\n",
      "   batch_size: 1\n",
      "   max_fps: 30\n",
      "\n",
      " Device-specific Performance Tips:\n",
      "   • Apple Silicon detected - optimized for MPS\n",
      "   • Nano model recommended for real-time performance\n",
      "   • Monitor thermal throttling on sustained loads\n",
      "   • Close other applications to maximize performance\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T23:52:53.354537Z",
     "start_time": "2025-05-28T23:52:53.349539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comprehensive demo and instructions\n",
    "def run_complete_demo():\n",
    "    \"\"\"\n",
    "    Complete demonstration of the CCTV analysis system\n",
    "    \"\"\"\n",
    "    print(\" CCTV Object Detection and Line Crossing Analysis Demo\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Demo configuration\n",
    "    demo_config = {\n",
    "        'model': 'YOLOv8 Nano',\n",
    "        'target_objects': list(detector.target_classes.values()),\n",
    "        'features': [\n",
    "            'Real-time object detection',\n",
    "            'Line crossing detection and counting',\n",
    "            'Multi-object tracking',\n",
    "            'Performance monitoring',\n",
    "            'IP camera support',\n",
    "            'Data export and reporting'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    print(\" System Capabilities:\")\n",
    "    for feature in demo_config['features']:\n",
    "        print(f\"   {feature}\")\n",
    "\n",
    "    print(f\"\\n🔧 Configuration:\")\n",
    "    print(f\"   Model: {demo_config['model']}\")\n",
    "    print(f\"   Target Objects: {', '.join(demo_config['target_objects'])}\")\n",
    "    print(f\"   Confidence Threshold: {detector.confidence_threshold}\")\n",
    "\n",
    "    print(f\"\\n Usage Instructions:\")\n",
    "    print(\"1. For video analysis:\")\n",
    "    print(\"   results = analyze_cctv_video('your_video.mp4')\")\n",
    "\n",
    "    print(\"\\n2. For real-time webcam:\")\n",
    "    print(\"   real_time_detection()\")\n",
    "\n",
    "    print(\"\\n3. For IP camera:\")\n",
    "    print(\"   ip_camera.analyze_ip_stream('rtsp://your.camera.url')\")\n",
    "\n",
    "    print(\"\\n4. Export results:\")\n",
    "    print(\"   data_exporter.export_crossing_data(results)\")\n",
    "    print(\"   data_exporter.create_summary_report(results, performance_monitor)\")\n",
    "\n",
    "    print(f\"\\n Demo Complete! System ready for presentation.\")\n",
    "    return demo_config\n",
    "\n",
    "\n",
    "def get_ip_camera_examples():\n",
    "    \"\"\"\n",
    "    Provide example IP camera URLs for common camera brands\n",
    "    \"\"\"\n",
    "    examples = {\n",
    "        'Generic RTSP': 'rtsp://username:password@192.168.1.100:554/stream1',\n",
    "        'Hikvision': 'rtsp://admin:password@192.168.1.100:554/Streaming/Channels/101',\n",
    "        'Dahua': 'rtsp://admin:password@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0',\n",
    "        'Axis': 'rtsp://root:password@192.168.1.100/axis-media/media.amp',\n",
    "        'Generic HTTP': 'http://192.168.1.100:8080/video.mjpg'\n",
    "    }\n",
    "\n",
    "    print(\" IP Camera URL Examples:\")\n",
    "    for brand, url in examples.items():\n",
    "        print(f\"   {brand}: {url}\")\n",
    "\n",
    "    print(\"\\n Remember to:\")\n",
    "    print(\"   • Replace username/password with actual credentials\")\n",
    "    print(\"   • Replace IP address with your camera's IP\")\n",
    "    print(\"   • Check your camera's documentation for exact URL format\")\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Run the complete demo\n",
    "demo_results = run_complete_demo()\n",
    "ip_examples = get_ip_camera_examples()\n",
    "\n",
    "print(\"\\n CCTV Analysis System Ready!\")"
   ],
   "id": "d531c4bb8118319e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CCTV Object Detection and Line Crossing Analysis Demo\n",
      "============================================================\n",
      " System Capabilities:\n",
      "   Real-time object detection\n",
      "   Line crossing detection and counting\n",
      "   Multi-object tracking\n",
      "   Performance monitoring\n",
      "   IP camera support\n",
      "   Data export and reporting\n",
      "\n",
      "🔧 Configuration:\n",
      "   Model: YOLOv8 Nano\n",
      "   Target Objects: person, bicycle, car, motorcycle, bus, truck\n",
      "   Confidence Threshold: 0.5\n",
      "\n",
      " Usage Instructions:\n",
      "1. For video analysis:\n",
      "   results = analyze_cctv_video('your_video.mp4')\n",
      "\n",
      "2. For real-time webcam:\n",
      "   real_time_detection()\n",
      "\n",
      "3. For IP camera:\n",
      "   ip_camera.analyze_ip_stream('rtsp://your.camera.url')\n",
      "\n",
      "4. Export results:\n",
      "   data_exporter.export_crossing_data(results)\n",
      "   data_exporter.create_summary_report(results, performance_monitor)\n",
      "\n",
      " Demo Complete! System ready for presentation.\n",
      " IP Camera URL Examples:\n",
      "   Generic RTSP: rtsp://username:password@192.168.1.100:554/stream1\n",
      "   Hikvision: rtsp://admin:password@192.168.1.100:554/Streaming/Channels/101\n",
      "   Dahua: rtsp://admin:password@192.168.1.100:554/cam/realmonitor?channel=1&subtype=0\n",
      "   Axis: rtsp://root:password@192.168.1.100/axis-media/media.amp\n",
      "   Generic HTTP: http://192.168.1.100:8080/video.mjpg\n",
      "\n",
      " Remember to:\n",
      "   • Replace username/password with actual credentials\n",
      "   • Replace IP address with your camera's IP\n",
      "   • Check your camera's documentation for exact URL format\n",
      "\n",
      " CCTV Analysis System Ready!\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
